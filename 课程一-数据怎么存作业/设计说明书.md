### 编写程序实现简单文件同步器

#### 开发环境

操作系统：版本: Windows 10 专业版	版本号: 20H2

开发语言：Java

集成开发环境：Idea

开发方式：测试驱动开发

#### 设计架构图

#### 详细设计

​	对于文件同步服务器设计，按照要求我们需要考虑以下几点

- 首先我们需要知道文件同步需要分为程序启动时候远程向本地同步以及之后程序运行过程中需要每隔一段时间将本地文件同步到远程服务器

- 对于程序启动时候远程文件向本地同步，可以分为以下几种情况

  | 本地文件                                 | 远程文件                   | 策略                                                         |
  | ---------------------------------------- | -------------------------- | ------------------------------------------------------------ |
  |                                          | 比本地多或者相比本地被修改 | 对于比本地多的文件，我们下载下来，对于相比本地，远程文件被修改的情况，我们暂时是直接覆盖。 |
  | 本地多余的文件，也就是相比远程多余的文件 |                            | 对于本地相比远程多余的文件，也就是远程缺少的文件，我们暂时不对做任何操作，然后在之后程序运行过程中将本地文件往远程同步时候将其上传 |

- 对于程序运行过程中本地文件往远程同步，可以分为以下情况

  | 本地文件             | 远程文件 | 策略                                       |
  | -------------------- | -------- | ------------------------------------------ |
  | 本地添加或修改的文件 |          | 一旦扫描到此类文件，我们将对其执行上传操作 |
  | 本地删除的文件       |          | 将删除远程库中此类文件                     |

- 之后我们需要考虑如何获取到本地文件所有名称，远程文件所有名称，以及本地文件与远程文件的比对，发现两边多余，缺少或者修改的文件

  - 获取本地文件名称，对于本地文件，我们通过递归来读取文件以及文件夹的名称
  - 对于远程文件，我们通过**s3.listObjects(listObjectsRequest);** 获取到远程文件的所有相关信息
  - 在考虑文件比对时候，考虑到对于修改了内容的文件，如果单纯用文件名称或者文件修改时间来得出文件是否改变的话，将会是不准确的，因此我们需要用文件的Etag值来进行比对；对于远程文件，在上一步我们可以获取到所以远程文件的Etag值，但是对于本地文件我们需要自己计算文件的Etag值，经过测试，对于本地没有进行分段上传的文件，只需要计算文件的md5值即可，但是对于分段上传的文件，我们需要分段计算得到每个分段的文件的md值之后，将他们按文件顺序连接到一起后，对其进行Base16编码，再进行md5值，最后再在最后添加**-md5s.size()**后即可得到分段文件的Etag，另外远程文件夹的所有Etag值都相等。
- 对于断点续传，我们分为上传时候的断点续传与下载时候的断点续传来讨论；对于上传时候的断点续传，主要依赖s3.listMultipartUploads()与s3.listParts()来实现断点续传；对于下载时候的断点续传，我们通过读取本地文件名称及文件大小与远程文件名称及大小进行对比，如果发现有同名称文件文件大小不一样，我们就将此类文件判定为程序停止时候未完成下载的文件，然后通过**long filePosition = localFile.length();**来从未下载位置继续下载文件
#### 核心代码

##### 1.读取某个文件夹下所有文件

###### 工具类代码

```java
package plj.liocna.club.util;

import java.io.File;
import java.util.ArrayList;
import java.util.List;

/**
 * @author licona
 * @date 2021/6/3
 */
public class ReadFiles {
    List<String> files = new ArrayList<>();
    /**
     * 读取某个文件夹下的所有文件
     */
    public List<String> readFiles(String path, String prefix) {
        File file = new File(path);
        File[] tempList = file.listFiles();

        for (File value : tempList) {
            if (value.isFile()) {
                files.add(value.getPath().substring(prefix.length()).replaceAll("\\\\", "/"));
            }
            if (value.isDirectory()) {
                readFiles(value.getPath(), prefix);
//                files.add(value.getPath() + "/");
            }
        }
        return files;
    }
}
```

###### 单元测试代码及结果

```java
package plj.licona.club;

import org.junit.Test;
import plj.liocna.club.util.ReadFiles;

import java.io.IOException;
import java.util.List;

public class ReadFileTest {
    @Test
    public void readFileTest() throws IOException {
        List<String> strings = new ReadFiles().readFiles("./liyuming-repository", "./liyuming-repository");
        for (int i = 0; i<strings.size(); i++) {
            System.out.println(strings.get(i));
        }
    }
}
```

###### 测试结果

```
/source/code-docs/docs/.nojekyll
/source/code-docs/docs/en-us/README.md
/source/code-docs/docs/en-us/_sidebar.md
/source/code-docs/docs/index.html
/source/code-docs/docs/README.md
/source/code-docs/docs/zh-cn/database/MySQL/index.md
/source/code-docs/docs/zh-cn/database/Redis/index.md
/source/code-docs/docs/zh-cn/fundamentals/操作系统/index.md
/source/code-docs/docs/zh-cn/fundamentals/算法与数据结构/index.md
/source/code-docs/docs/zh-cn/fundamentals/计算机网络/index.md
/source/code-docs/docs/zh-cn/language/java/java基础/index.md
/source/code-docs/docs/zh-cn/language/java/JVM/index.md
/source/code-docs/docs/zh-cn/language/java/容器/index.md
/source/code-docs/docs/zh-cn/language/java/并发/index.md
/source/code-docs/docs/zh-cn/README.md
/source/code-docs/docs/zh-cn/search/ElasticSearch/README.md
/source/code-docs/docs/zh-cn/search/Solr/README.md
/source/code-docs/docs/zh-cn/system-design/分布式与微服务/index.md
/source/code-docs/docs/zh-cn/system-design/常用框架/index.md
/source/code-docs/docs/zh-cn/system-design/认证授权/index.md
/source/code-docs/docs/zh-cn/system-design/高可用/index.md
/source/code-docs/docs/zh-cn/system-design/高并发/index.md
/source/code-docs/docs/zh-cn/utils/Docker/index.md
/source/code-docs/docs/zh-cn/utils/Git/index.md
/source/code-docs/docs/zh-cn/utils/Idea/index.md
/source/code-docs/docs/zh-cn/utils/Maven/index.md
/source/code-docs/docs/zh-cn/utils/SVG/index.md
/source/code-docs/docs/_navbar.md
/source/code-docs/docs/_sidebar.md
/source/code-docs/package-lock.json
/source/code-docs/package.json
/test/test-multipartupload

Process finished with exit code 0
```

##### 2.计算本地分段上传时候文件的Etag值

###### 工具类代码

```java
package plj.liocna.club.util;

import com.amazonaws.util.Md5Utils;
import com.google.common.hash.Hasher;
import com.google.common.hash.Hashing;
import com.google.common.io.BaseEncoding;

import java.io.*;
import java.util.ArrayList;
import java.util.List;

/**
 * @author licona
 * @date 2021/6/3
 */
public class MultipartFileEtag {
    public static String getMultipartFileEtag(String inputFile, int bufferSize) {
        long contentLength = new File(inputFile).length();
        FileInputStream fis = null;
        List<String> md5s = new ArrayList<>();
        try {
            fis = new FileInputStream(inputFile);
            // 文件读取缓存
            byte[] buffer = new byte[bufferSize];
            int fileNum = 0;
            // 大文件切割成小文件
            while ((fis.read(buffer, 0, bufferSize)) != -1) {
                md5s.add(ByteToHex.bytesToHex(Md5Utils.computeMD5Hash(subBytes(buffer, 0, bufferSize))));
                fileNum++;
                bufferSize = Math.toIntExact(Math.min(bufferSize, contentLength - (long) fileNum * bufferSize));
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            if (fis != null) {
                try {
                    fis.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            if (fis != null) {
                try {
                    fis.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
        StringBuilder stringBuilder = new StringBuilder();
        for (String md5 : md5s) {
            stringBuilder.append(md5);
        }
        String hex = stringBuilder.toString();
        byte[] raw = BaseEncoding.base16().decode(hex.toUpperCase());
        Hasher hasher = Hashing.md5().newHasher();
        hasher.putBytes(raw);
        String digest = hasher.hash().toString();

        return digest + "-" + md5s.size();
    }

    public static byte[] subBytes(byte[] src, int begin, int count) {
        byte[] bs = new byte[count];
        System.arraycopy(src, begin, bs, 0, count);
        return bs;
    }
}
```

###### 单元测试代码及结果(此时我们假设文件按照7M进行切分)

```java
package plj.licona.club;

import org.junit.Test;
import plj.liocna.club.util.MultipartFileEtag;

import java.io.FileNotFoundException;

/**
 * @author licona
 * @date 2021/6/3
 */
public class MultipartFileEtagTest {
    @Test
    public void multipartFileEtagTest() throws FileNotFoundException {
        String a = MultipartFileEtag.getMultipartFileEtag("liyuming-repository/test/test-multipartupload", 7 << 20);
        System.out.println(a);
    }
}
```

###### 测试结果

如果我们在S3 Browser中观察我们会发现我们计算的Etag值与S3 Browser是一样的

````
ee9dedccfec5512ff80bee07df9bc6ea-3
````

##### 3.本地文件与远程文件比对

###### 工具类代码

```java
package plj.licona.club;

import com.amazonaws.ClientConfiguration;
import com.amazonaws.auth.AWSStaticCredentialsProvider;
import com.amazonaws.auth.BasicAWSCredentials;
import com.amazonaws.client.builder.AwsClientBuilder;
import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.AmazonS3ClientBuilder;
import com.amazonaws.services.s3.model.*;
import org.junit.Test;
import plj.liocna.club.util.ByteToHex;
import plj.liocna.club.util.MultipartFileEtag;
import plj.liocna.club.util.ReadFiles;

import java.io.File;
import java.io.IOException;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import com.amazonaws.util.Md5Utils;

/**
 * @author licona
 * @date 2021/6/3
 */
public class MD5Test {
    private final static String bucketName = "liyuming-repository";
    private final static String filePath = "./liyuming-repository/";
    private final static String accessKey = "9955B832123E755E5E98";
    private final static String secretKey = "WzI3RTA1RDEyRjc1NDRERjU4NDQwNDg4MzVBNTcz";
    private final static String serviceEndpoint = "http://10.16.0.1:81";
    private final static String signingRegion = "";

    private static long partSize = 5 << 20;

    @Test
    public void test() throws IOException {
        final BasicAWSCredentials credentials = new BasicAWSCredentials(accessKey, secretKey);
        final ClientConfiguration ccfg = new ClientConfiguration().withUseExpectContinue(true);

        final AwsClientBuilder.EndpointConfiguration endpoint = new AwsClientBuilder.EndpointConfiguration(serviceEndpoint, signingRegion);

        final AmazonS3 s3 = AmazonS3ClientBuilder.standard()
                .withCredentials(new AWSStaticCredentialsProvider(credentials)).withClientConfiguration(ccfg)
                .withEndpointConfiguration(endpoint).withPathStyleAccessEnabled(true).build();

        // 获取到远程文件列表和文件ETag值
        ListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(bucketName);
        ObjectListing objects = s3.listObjects(listObjectsRequest);
        Map<String, String> remoteFiles = new HashMap<>();
        do {
            for (S3ObjectSummary objectSummary : objects.getObjectSummaries()) {
                remoteFiles.put(objectSummary.getKey(), objectSummary.getETag());
            }
            objects = s3.listNextBatchOfObjects(objects);
        } while (objects.isTruncated());
        //获取本地文件列表并计算哈希值
        Map<String, String> localFiles = new HashMap<>();
        List<String> strings = new ReadFiles().readFiles(filePath, filePath);
        for (int i = 0; i < strings.size(); i++) {
            File file = new File(filePath + strings.get(i));
            if (file.length() > partSize) {
                localFiles.put(strings.get(i), MultipartFileEtag.getMultipartFileEtag(filePath + strings.get(i), (int) partSize));
            } else {
                localFiles.put(strings.get(i), ByteToHex.bytesToHex(Md5Utils.computeMD5Hash(file)));
            }
        }

        for (Map.Entry<String, String> entry : localFiles.entrySet()) {
            if (entry.getValue().equals(remoteFiles.get(entry.getKey()))) {
                System.out.print("same ");
            } else {
                System.out.println(entry);
                System.out.println(remoteFiles.get(entry.getKey()));
                System.out.println("本地文件与远程文件不一样");
            }
        }
    }
}
```

###### 测试结果

我们将本地与远程文件进行比对，如果相同就输出same，不同就输出本地文件与远程文件不一样

```
same same same same same same same source/code-docs/package.json=dd5827b64bc128f2ae2f418e41955087
5ce18fb12926e452598e98822744fc80
本地文件与远程文件不一样
same same same same same same same same same same same same same same same same same same same same same same same same 
Process finished with exit code 0
```

##### 4.分段上传

###### 工具类代码

```java
package plj.liocna.club.util;

import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.model.*;

import java.io.File;
import java.util.ArrayList;

public class MultipartUpload {

    public static void multipartUpload(AmazonS3 s3, String bucketName, String filePath, String keyName, long partSize) {
        // Create a list of UploadPartResponse objects. You get one of these
        // for each part upload.
        ArrayList<PartETag> partETags = new ArrayList<PartETag>();
        File file = new File(filePath);
        long contentLength = file.length();
        String uploadId = null;
        try {
            // Step 1: Initialize.
            InitiateMultipartUploadRequest initRequest = new InitiateMultipartUploadRequest(bucketName, keyName);
            uploadId = s3.initiateMultipartUpload(initRequest).getUploadId();

            System.out.format("Created upload ID was %s\n", uploadId);

            // Step 2: Upload parts.
            long filePosition = 0;
            for (int i = 1; filePosition < contentLength; i++) {
                // Last part can be less than 5 MB. Adjust part size.
                partSize = Math.min(partSize, contentLength - filePosition);

                // Create request to upload a part.
                UploadPartRequest uploadRequest = new UploadPartRequest().withBucketName(bucketName).withKey(keyName)
                        .withUploadId(uploadId).withPartNumber(i).withFileOffset(filePosition).withFile(file)
                        .withPartSize(partSize);

                // Upload part and add response to our list.
                System.out.format("Uploading part %d\n", i);
                partETags.add(s3.uploadPart(uploadRequest).getPartETag());

                filePosition += partSize;
            }

            // Step 3: Complete.
            System.out.println("Completing upload");
            CompleteMultipartUploadRequest compRequest = new CompleteMultipartUploadRequest(bucketName, keyName,
                    uploadId, partETags);

            s3.completeMultipartUpload(compRequest);

            for( int i=0; i<partETags.size(); i++) {
                System.out.println(partETags.get(i).getETag());
            }
        } catch (Exception e) {
            System.err.println(e.toString());
            if (uploadId != null && !uploadId.isEmpty()) {
                // Cancel when error occurred
                System.out.println("Aborting upload");
                s3.abortMultipartUpload(new AbortMultipartUploadRequest(bucketName, keyName, uploadId));
            }
            System.exit(1);
        }
        System.out.println("Done!");
    }
}
```

具体测试代码见代码源文件

##### 5.分段下载

与分段上传类似，具体代码见源文件

##### 6.断点续传上传

主要依赖s3.listMultipartUploads()与s3.listParts()来实现断点续传

```java
package plj.liocna.club.util;

import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.model.*;
import com.amazonaws.services.s3.model.MultipartUpload;

import java.io.File;
import java.util.ArrayList;
import java.util.List;

/**
 * @author licona
 * @date 2021/6/3
 */
public class BreakpointUpload {
    public static void breakpointContinuation(AmazonS3 s3, String bucketName, String filePath, long partSize) {
        ArrayList<PartETag> partETags = new ArrayList<PartETag>();
        MultipartUploadListing multipartUploadListing = s3.listMultipartUploads(new ListMultipartUploadsRequest(bucketName));
        List<MultipartUpload> multipartUploads = multipartUploadListing.getMultipartUploads();

        for (int i = 0; i < multipartUploads.size(); i++) {
            System.out.println(multipartUploads.get(i).getKey());
            List<PartSummary> parts = s3.listParts(new ListPartsRequest(bucketName, multipartUploads.get(i).getKey(), multipartUploads.get(i).getUploadId())).getParts();
            for (int j = 0; j < parts.size(); j++) {
                partETags.add(new PartETag(parts.get(j).getPartNumber(), parts.get(j).getETag()));
            }
            File file = new File(filePath + multipartUploads.get(i).getKey());

            long contentLength = file.length();
            String uploadId = multipartUploads.get(i).getUploadId();
            try {
                // Step 1: Initialize.
                System.out.format("Created upload ID was %s\n", uploadId);

                // Step 2: Upload parts.
                long filePosition = parts.size() * partSize;
                for (int k = parts.size() + 1; filePosition < contentLength; k++) {
                    // Last part can be less than 5 MB. Adjust part size.
                    partSize = Math.min(partSize, contentLength - filePosition);

                    // Create request to upload a part.
                    UploadPartRequest uploadRequest = new UploadPartRequest().withBucketName(bucketName).withKey(multipartUploads.get(i).getKey())
                            .withUploadId(uploadId).withPartNumber(k).withFileOffset(filePosition).withFile(file)
                            .withPartSize(partSize);

                    // Upload part and add response to our list.
                    System.out.format("Uploading part %d\n", k);
                    partETags.add(s3.uploadPart(uploadRequest).getPartETag());

                    filePosition += partSize;
                }

                // Step 3: Complete.
                System.out.println("Completing upload");
                CompleteMultipartUploadRequest compRequest = new CompleteMultipartUploadRequest(bucketName, multipartUploads.get(i).getKey(),
                        multipartUploads.get(i).getUploadId(), partETags);

                s3.completeMultipartUpload(compRequest);
            } catch (Exception e) {
                System.err.println(e.toString());
                if (uploadId != null && !uploadId.isEmpty()) {
                    // Cancel when error occurred
                    System.out.println("Aborting upload");
                    s3.abortMultipartUpload(new AbortMultipartUploadRequest(bucketName, multipartUploads.get(i).getKey(), uploadId));
                }
                System.exit(1);
            }
            System.out.println("Done!");
        }
    }
}
```

###### 测试输出

```
----------------------------首先我们处理之前程序运行时候断点上传问题-------------------------------
test/test-multipartupload
Created upload ID was 2~2v33HyTns0NWMiYKKzzP-2V7EX9hFRf
Uploading part 4
Completing upload
Done!
----------------------------断点上传问题处理完成------------------------------
```

##### 7.断点续传下载

```java
package plj.liocna.club.util;

import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.model.*;

import java.io.File;
import java.io.IOException;
import java.io.RandomAccessFile;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class BreakpointDownload {
    public static void breakpointContinuation(AmazonS3 s3, String bucketName, String filePath, long partSize) throws IOException {
        // 获取到远程文件列表和文件ETag值
        ListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(bucketName);
        ObjectListing objects = s3.listObjects(listObjectsRequest);
        Map<String, Long> remoteFiles = new HashMap<>();
        do {
            for (S3ObjectSummary objectSummary : objects.getObjectSummaries()) {
                if((objectSummary.getKey().lastIndexOf("/") != objectSummary.getKey().length() - 1)) {
                    remoteFiles.put(objectSummary.getKey(), objectSummary.getSize());
                }
            }
            objects = s3.listNextBatchOfObjects(objects);
        } while (objects.isTruncated());
        //获取本地文件列表并计算哈希值
        Map<String, Long> localFiles = new HashMap<>();
        List<String> strings = new ReadFiles().readFiles(filePath, filePath);
        for (int i = 0; i < strings.size(); i++) {
            File file = new File(filePath + strings.get(i));
            localFiles.put(strings.get(i), file.length());
        }

        List<String> interruptedDownloadFilesKey = new ArrayList<>();
        for (Map.Entry<String,Long> entry: localFiles.entrySet()) {
            if(entry.getValue()!=null && remoteFiles.get(entry.getKey())!=null && !remoteFiles.get(entry.getKey()).equals(entry.getValue())) {
                System.out.println("被中断的文件名称: " + entry.getKey());
                interruptedDownloadFilesKey.add(entry.getKey());
            }
        }

        for (int j = 0; j < interruptedDownloadFilesKey.size(); j++) {
            breakpointDownload(s3, bucketName, filePath, interruptedDownloadFilesKey.get(j), partSize);
        }



    }

    public static void breakpointDownload(AmazonS3 s3, String bucketName, String filePath, String keyName, Long partSize) {
        // 首先读取本地已经下载下来的文件
        File localFile = new File(filePath + keyName);
        S3Object o = null;
        S3ObjectInputStream s3is = null;
        RandomAccessFile randomAccessFile = null;
        try {
            // Step 1: Initialize.
            ObjectMetadata oMetaData = s3.getObjectMetadata(bucketName, keyName);
            final long contentLength = oMetaData.getContentLength();
            final GetObjectRequest downloadRequest =
                    new GetObjectRequest(bucketName, keyName);

            randomAccessFile = new RandomAccessFile(filePath + keyName, "rw");
            // 将写文件指针置于文件尾部
            randomAccessFile.seek(randomAccessFile.length());

            // Step 2: Download parts.
            System.out.println("我们从根据本地文件大小来从未下载部分开始继续下载文件");
            System.out.println("目前已下载"+ localFile.getName() +"百分比:" + (double)localFile.length()/oMetaData.getContentLength() * 100 + "%");
            long filePosition = localFile.length();
            for (int i = 1; filePosition < contentLength; i++) {
                // Last part can be less than 5 MB. Adjust part size.
                partSize = Math.min(partSize, contentLength - filePosition);

                // Create request to download a part.
                downloadRequest.setRange(filePosition, filePosition + partSize);
                o = s3.getObject(downloadRequest);

                // download part and save to local file.
                System.out.format("Downloading part %d\n", i);

                filePosition += partSize+1;
                s3is = o.getObjectContent();
                byte[] read_buf = new byte[64 * 1024];
                int read_len = 0;
                while ((read_len = s3is.read(read_buf)) > 0) {
                    randomAccessFile.write(read_buf, 0, read_len);
                }
            }

            System.out.println(localFile.length());

            // Step 3: Complete.
            System.out.println("Completing download");

            System.out.format("save %s to %s\n", keyName, filePath);
        } catch (Exception e) {
            System.err.println(e.toString());

            System.exit(1);
        } finally {
            if (s3is != null) try { s3is.close(); } catch (IOException e) { }
            if (randomAccessFile != null) try { randomAccessFile.close(); } catch (IOException e) { }
        }

    }
}

```

###### 测试输出

```
----------------------------首先我们处理之前程序运行时候断点下载问题-------------------------------
被中断的文件名称: test/test-multipartupload
我们从根据本地文件大小来从未下载部分开始继续下载文件
目前已下载test-multipartupload百分比:26.89828342980391%
Downloading part 1
Downloading part 2
Downloading part 3
68743067
Completing download
save test/test-multipartupload to C:/liyuming-repository/
----------------------------断点续传之下载问题处理完成------------------------------
```

##### 8.删除远程文件

```java
package plj.liocna.club.util;

import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.model.DeleteObjectRequest;

/**
 * @author licona
 * @date 2021/6/3
 */
public class DeleteRemoteFile {
    public static void deleteRemoteFile(AmazonS3 s3, String bucketName, String keyName) {
        DeleteObjectRequest deleteObjectRequest = new DeleteObjectRequest(bucketName, keyName);
        s3.deleteObject(deleteObjectRequest);
    }
}
```

#### 作业要求

##### 1. 指定本地某个目录与S3的某个Bucket进行文件同步。

由于我们采用测试驱动开发，因此在开发过程中我们将指定代码根目录下的 /liyuming-repository 与远程liyuming-repository Bucket进行同步，之后在编写项目代码时候将采用C:\\liyuming-repository本地库与远程liyuming-repository进行同步

##### 2.程序启动时把Bucket中的文件同步到本地，需要解决文件冲突。

程序启动时我们会将文件同步到本地，此过程相当于用户点击某个从远程仓库同步文件到本地的操作按钮，对于本地缺少的文件，我们将进行下载，对于本地添加的文件，我们将不采取任何操作，对于本地修改的文件，我们将会重新下载并覆盖本地文件。

##### 3.本地添加，修改了文件，需要上传到S3；本地删除了文件，也要删除S3上对应的文件。

在从远程同步文件到本地后。我们会每隔三十秒对本地文件进行扫描，对于本地添加或修改的文件我们将会上传到远程，对于本地删除的文件，我们将会删除远程仓库的文件。

##### 4.对于超过20MB的文件，需要使用分块上传/下载，传输中断，程序重启可以继续原来的进度。

对于断点续传，我们分为上传时候的断点续传与下载时候的断点续传来讨论；对于上传时候的断点续传，主要依赖s3.listMultipartUploads()与s3.listParts()来实现断点续传；对于下载时候的断点续传，我们通过读取本地文件名称及文件大小与远程文件名称及大小进行对比，如果发现有同名称文件文件大小不一样，我们就将此类文件判定为程序停止时候未完成下载的文件，然后通过**long filePosition = localFile.length();**来从未下载位置继续下载文件。

